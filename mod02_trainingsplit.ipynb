{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee65a5ae",
   "metadata": {},
   "source": [
    "# Module 02: Training Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a6bbc0",
   "metadata": {},
   "source": [
    "### Load necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d064a85-fc6d-448e-abae-0076b739f0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from ISLP.models import summarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060d508d",
   "metadata": {},
   "source": [
    "### Create helper functions for computing predictions and the mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54edc30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(X, model):\n",
    "    '''\n",
    "    The built-in \"get_prediction\" tool in ISLP returns an array, so this is just a wrapper which converts the result to a dataframe.\n",
    "    '''\n",
    "    predictions_df = pd.DataFrame(model.get_prediction(X).predicted, columns=['y_hat'], index=X.index)\n",
    "    return predictions_df['y_hat']\n",
    "\n",
    "def mse(y, y_hat):\n",
    "    '''\n",
    "    Returns the mean squared error, which we will use to evaluate how well a linear regression model fits a dataset.\n",
    "\n",
    "    The details of this function will be explored further in module 04.\n",
    "    '''\n",
    "    # calculate the residual error for each individual record\n",
    "    resid = y - y_hat\n",
    "    # square the residual (hence \"squared error\")\n",
    "    sq_resid = resid**2\n",
    "    # calculate the sum of squared errors\n",
    "    SSR = sum(sq_resid)\n",
    "    # divide by the number of records to get the mean squared error\n",
    "    MSE = SSR / y.shape[0]\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc0b929-424c-4056-ac14-e8e9c2d25cb6",
   "metadata": {},
   "source": [
    "### Randomly generate a dataset using the equation y = x - 2x^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babe6dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Always specify a seed so that the data can be regenerated\n",
    "# DON'T change anything in this cell.\n",
    "seed = 314\n",
    "\n",
    "# Create a random number generator called rng\n",
    "rng = np.random.default_rng(seed)\n",
    "\n",
    "# Use the random number generator to create x- and y-coordinates\n",
    "x = rng.normal(size=150)\n",
    "y = x - 2 * x**2 + rng.normal(size=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32b385d",
   "metadata": {},
   "source": [
    "### Create a dataframe we can use to build three different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64f0723-dfde-4e09-8578-c3382f3ee5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll need a collection of independent variables. We'll use x, x^2, x^3, and a constant (which will be used to calculate the intercept)\n",
    "new_x = pd.DataFrame(np.column_stack((x**0, x, x**2, x**3)), columns=['intercept','x','x_sq','x_cu'])\n",
    "\n",
    "# print the dataframe\n",
    "new_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9690396f",
   "metadata": {},
   "source": [
    "### Split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ed4047-8806-47df-b82d-fbc96eb4e954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that we need to choose a random seed and the percent of records withheld for testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(new_x,\n",
    "                                                    y,\n",
    "                                                    random_state=314159,\n",
    "                                                    test_size=0.33,\n",
    "                                                    shuffle=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8d31ef",
   "metadata": {},
   "source": [
    "### Graph the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddef896-b7ca-4f71-8600-35776dd440b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's important to do this after the train/test split is created. We shouldn't look at data that's withheld for testing.\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x_train['x'],y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf18cce2",
   "metadata": {},
   "source": [
    "### First we'll a quadratic model, which should be appropriate since the data was randomly generated based on a quadratic equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225faa83-460d-4af2-9dff-e34beaa4a11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a quadratic model\n",
    "model_quad = sm.OLS(y_train, x_train[['intercept','x','x_sq']])\n",
    "results_quad = model_quad.fit()\n",
    "summarize(results_quad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d71075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "x_train['pred_sq'] = predict(x_train[['intercept', 'x', 'x_sq']], results_quad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b26cf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions as solid green line, along with the original training data\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x_train['x'],y_train)\n",
    "quadratic = x_train[['x','pred_sq']].sort_values('x')\n",
    "ax.plot(quadratic['x'],quadratic['pred_sq'], color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8393626d",
   "metadata": {},
   "source": [
    "### Next we'll create an underfit model and observe the performance on training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca53097a-79b6-4d8d-9f3e-faba8f49b370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a linear model\n",
    "model_lin = sm.OLS(y_train, x_train[['intercept','x']])\n",
    "results_lin =  model_lin.fit()\n",
    "summarize(results_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995a9cbc-1d45-40bc-8e64-8e3b956123b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model predictions\n",
    "predictions_lin_train = predict(x_train[['intercept', 'x']], results_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4c1cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions as solid *orange* line\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x_train['x'],y_train)\n",
    "linear = x_train[['x','pred_sq']].sort_values('x')\n",
    "ax.plot(linear['x'],predictions_lin_train.sort_values(), color='orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df2a192",
   "metadata": {},
   "source": [
    "### And lastly we'll build an overfit model and observe the performance on training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafdbfbf-e9c7-4d59-92c4-0e7f74022096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a cubic model\n",
    "model_cubic = sm.OLS(y_train, x_train[['intercept','x','x_sq','x_cu']])\n",
    "results_cubic = model_cubic.fit()\n",
    "summarize(results_cubic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828ef9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "x_train['pred_cu'] = predict(x_train[['intercept', 'x', 'x_sq', 'x_cu']], results_cubic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938de1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions as solid *red* line\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x_train['x'],y_train)\n",
    "cubic =  x_train[['x','pred_cu']].sort_values('x')\n",
    "ax.plot(cubic['x'],cubic['pred_cu'], color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8034ef2",
   "metadata": {},
   "source": [
    "### After observing the resulting three plots on the training set, how do the models compare? Is one clearly the best? Is one clearly the worst?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e919ee6e",
   "metadata": {},
   "source": [
    "#fill-in\n",
    "Type your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc2883c",
   "metadata": {},
   "source": [
    "### Now we'll calculate the errors (MSE) for each model on the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4c4b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the MSE on the training set for each model\n",
    "predictions_lin_train = predict(x_train[['intercept', 'x']], results_lin)\n",
    "predictions_quad_train = predict(x_train[['intercept', 'x', 'x_sq']], results_quad)\n",
    "predictions_cubic_train = predict(x_train[['intercept', 'x', 'x_sq', 'x_cu']], results_cubic)\n",
    "\n",
    "print('mse train linear   :',mse(y_train, predictions_lin_train))\n",
    "print('mse train quadratic:',mse(y_train, predictions_quad_train))\n",
    "print('mse train cubic    :',mse(y_train, predictions_cubic_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476c0fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the MSE on the test set for each model\n",
    "predictions_lin_test = #fill-in\n",
    "predictions_quad_test = #fill-in\n",
    "predictions_cubic_test = #fill-in\n",
    "\n",
    "print('mse test linear   :',mse(y_test, predictions_lin_test))\n",
    "print('mse test quadratic:',mse(y_test, predictions_quad_test))\n",
    "print('mse test cubic    :',mse(y_test, predictions_cubic_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b05ec42",
   "metadata": {},
   "source": [
    "### Describe the results for each of the three models in terms of their performance on training data and on test data. Which model is most likely underfit? Which is most likely overfit?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb74c23",
   "metadata": {},
   "source": [
    "#fill-in\n",
    "Type your answer here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
